{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "barsize = '{l_bar}{bar:10}{r_bar}{bar:-10b}'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mcintire.csv', 'kaggle.csv', 'buzzfeed.csv', 'politifact.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(r\"final/mcintire.csv\")\n",
    "data2 = pd.read_csv(r\"final/buzzfeed.csv\")\n",
    "data3 = pd.read_csv(r\"final/politifact.csv\")\n",
    "data4 = pd.read_csv(r\"final/kaggle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample(frac = 1)\n",
    "dataset.reset_index(drop =True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    2388\n",
       "fake    2388\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2388 2388\n"
     ]
    }
   ],
   "source": [
    "real = dataset[dataset['label'] == 'real']\n",
    "fake = dataset[dataset['label'] == 'fake']\n",
    "print(len(fake), len(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 100\n",
    "# real = real.sample(n = total)\n",
    "# fake = fake.sample(n = total)\n",
    "# print(len(fake), len(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([real, fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real    2388\n",
       "fake    2388\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reset_index(drop =True, inplace = True)\n",
    "dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "dataset['title'] = dataset['title'].apply(lambda x: re.findall(\"[A-Za-z0-9]+\", str(x)))\n",
    "dataset['title'] = dataset['title'].apply(lambda x: \" \".join(x).lower())\n",
    "dataset['text'] = dataset['text'].apply(lambda x: re.findall(\"[A-Za-z0-9]+\", str(x)))\n",
    "dataset['text'] = dataset['text'].apply(lambda x: \" \".join(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()\n",
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x : tweet_cleaner(str(x)))\n",
    "df['text'] = df['text'].apply(lambda x : tweet_cleaner(str(x)))\n",
    "# df['meta_data'] = df['meta_data'].apply(tweet_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_X(row):\n",
    "    try:\n",
    "        return row['title']+\" \"+row[\"text\"]\n",
    "    except: print(\"error\", row)\n",
    "        #giving out the error fields.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"all_X\"]= df.apply(all_X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['all_X', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['all_X', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign text to X variable and labels to y\n",
    "\n",
    "X = df.all_X\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Count Vectorizer\n",
    "count_vec = CountVectorizer(lowercase = True, stop_words=\"english\", min_df = 2, ngram_range = (1, 1))\n",
    "#Fit Count Vectorizer\n",
    "dtm_cv = count_vec.fit_transform(X)\n",
    "#Convert it to a pandas data frame\n",
    "df_cv = pd.DataFrame(dtm_cv.toarray(), columns=count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aab</th>\n",
       "      <th>aap</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarp</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abaaoud</th>\n",
       "      <th>aback</th>\n",
       "      <th>abadi</th>\n",
       "      <th>...</th>\n",
       "      <th>zu</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zucman</th>\n",
       "      <th>zuesse</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyuganov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aab  aap  aaron  aarp  ab  aba  abaaoud  aback  abadi  ...  zu  zucker  \\\n",
       "0   0    0    0      0     0   0    0        0      0      0  ...   0       0   \n",
       "1   0    0    0      0     0   0    0        0      0      0  ...   0       0   \n",
       "2   0    0    0      0     0   0    0        0      0      0  ...   0       0   \n",
       "3   0    0    0      0     0   0    0        0      0      0  ...   0       0   \n",
       "4   0    0    0      0     0   0    0        0      0      0  ...   0       0   \n",
       "\n",
       "   zuckerberg  zucman  zuesse  zulu  zurich  zwick  zy  zyuganov  \n",
       "0           0       0       0     0       0      0   0         0  \n",
       "1           0       0       0     0       0      0   0         0  \n",
       "2           0       0       0     0       0      0   0         0  \n",
       "3           0       0       0     0       0      0   0         0  \n",
       "4           0       0       0     0       0      0   0         0  \n",
       "\n",
       "[5 rows x 33426 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776, 33426)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_cv, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3343, 33426) (1433, 33426)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,\n",
    "     x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3853652477264404\n",
      "Model accuracy : 88.70%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.90      0.87      0.89       727\n",
      "        real       0.87      0.90      0.89       706\n",
      "\n",
      "    accuracy                           0.89      1433\n",
      "   macro avg       0.89      0.89      0.89      1433\n",
      "weighted avg       0.89      0.89      0.89      1433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize model\n",
    "import time\n",
    "tic = time.time()\n",
    "model = MultinomialNB()\n",
    "#Fit model with df_cv and y\n",
    "model.fit(x_train, y_train)\n",
    "#score the model\n",
    "y_pred = model.predict(x_test)\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "# accuracy = cross_val_score(estimator = model, X = x_train, y = y_train, cv=10)\n",
    "print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(accuracy.mean()*100))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288.43796944618225\n",
      "Model accuracy : 90.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.89      0.92      0.90       727\n",
      "        real       0.92      0.88      0.90       706\n",
      "\n",
      "    accuracy                           0.90      1433\n",
      "   macro avg       0.90      0.90      0.90      1433\n",
      "weighted avg       0.90      0.90      0.90      1433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "svm = SVC(C=100, gamma = 0.0001)\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "# tic = time.time()\n",
    "# accuracy = cross_val_score(estimator = svm, X = x_train, y = y_train, cv=10)\n",
    "# toc = time.time()\n",
    "# print(toc - tic)\n",
    "print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(acuracy.mean()*100))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defining parameter range \n",
    "# param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "#                'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "#               'kernel': ['rbf']}  \n",
    "# grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "# grid.fit(x_train, y_train)\n",
    "# # print best parameter after tuning \n",
    "# print(grid.best_params_) \n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.89146995544434\n",
      "Model accuracy : 88.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.87      0.91      0.89       727\n",
      "        real       0.90      0.86      0.88       706\n",
      "\n",
      "    accuracy                           0.88      1433\n",
      "   macro avg       0.89      0.88      0.88      1433\n",
      "weighted avg       0.89      0.88      0.88      1433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "abc = AdaBoostClassifier(n_estimators = 50,learning_rate = 1)\n",
    "abc.fit(x_train, y_train)\n",
    "y_pred = abc.predict(x_test)\n",
    "toc = time.time()\n",
    "print(toc - tic)\n",
    "# tic = time.time()\n",
    "# acuracy = cross_val_score(estimator = abc, X = x_train, y = y_train, cv = 10)\n",
    "# toc = time.time()\n",
    "# print(toc - tic)\n",
    "y_pred = abc.predict(x_test)\n",
    "print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(acuracy.mean()*100))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc = GradientBoostingClassifier(max_depth = 2)\n",
    "# gbc.fit(x_train, y_train)\n",
    "# y_pred = gbc.predict(x_test)\n",
    "# accuracy = cross_val_score(estimator = gbc, X = x_train, y = y_train, cv=10)\n",
    "# print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(accuracy.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dTree = DecisionTreeClassifier()\n",
    "# dTree.fit(x_train,y_train)\n",
    "# y_pred = dTree.predict(x_test)\n",
    "# accuracy = cross_val_score(estimator = dTree, X = x_train, y = y_train, cv = 10)\n",
    "# print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(accuracy.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = dTree.cost_complexity_pruning_path(x_train, y_train)\n",
    "# ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# trees = []\n",
    "# for ccp_alpha in tqdm(ccp_alphas, bar_format = barsize):\n",
    "#     tree  = DecisionTreeClassifier(random_state = 0, ccp_alpha = ccp_alpha)\n",
    "#     tree.fit(x_train, y_train)\n",
    "#     trees.append(tree)\n",
    "    \n",
    "# train_score = [tree.score(x_train, y_train) for tree in tqdm(trees, bar_format = barsize)]\n",
    "# test_score = [tree.score(x_test, y_test) for tree in tqdm(trees, bar_format = barsize)]\n",
    "# # cross_val_scores = [cross_val_score(estimator = tree, X = x_train, y = y_train, cv = 4).mean() for tree in tqdm(trees, bar_format = barsize)]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_xlabel('alpha')\n",
    "# ax.set_ylabel('accuracy')\n",
    "# ax.set_title('accuracy vs alpha for training and testing sets')\n",
    "# ax.plot(ccp_alphas, train_score, marker = 'o', label = 'train')\n",
    "# ax.plot(ccp_alphas, test_score, marker = 'x', label = 'test')\n",
    "# # ax.plot(ccp_alphas, cross_val_scores, marker = '*', label = 'cross_val')\n",
    "# plt.legend(['train', 'test', 'cross'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dTree = DecisionTreeClassifier(ccp_alpha = 0.03)\n",
    "# dTree.fit(x_train,y_train)\n",
    "# y_pred = dTree.predict(x_test)\n",
    "# # accuracy = cross_val_score(estimator = dTree, X = x_train, y = y_train, cv = 10)\n",
    "# print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(accuracy.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #neighbors randomly taken\n",
    "# knn = KNeighborsClassifier(n_neighbors = 7) \n",
    "# knn.fit(x_train, y_train) \n",
    "# y_pred = knn.predict(x_test)\n",
    "# accuracy = cross_val_score(estimator = knn, X = x_train, y = y_train, cv = 10)\n",
    "# print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(accuracy.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_rate = []  \n",
    "# # Will take some time \n",
    "# for i in tqdm(range(1, 40), bar_format = barsize): \n",
    "      \n",
    "#     knn = KNeighborsClassifier(n_neighbors = i) \n",
    "#     knn.fit(x_train, y_train) \n",
    "#     pred_i = knn.predict(x_test) \n",
    "#     error_rate.append(np.mean(pred_i != y_test)) \n",
    "\n",
    "# plt.figure(figsize =(10, 6)) \n",
    "# plt.plot(range(1, 40), error_rate, color ='blue', \n",
    "#                 linestyle ='dashed', marker ='o', \n",
    "#          markerfacecolor ='red', markersize = 10) \n",
    "  \n",
    "# plt.title('Error Rate vs. K Value') \n",
    "# plt.xlabel('K') \n",
    "# plt.ylabel('Error Rate') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error rate for k=1 is very high\n",
    "#error rate is decreaing after k = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors = 36) \n",
    "# knn.fit(x_train, y_train) \n",
    "# y_pred = knn.predict(x_test)\n",
    "# accuracy = cross_val_score(estimator = knn, X = x_train, y = y_train, cv=10)\n",
    "# print(\"Model accuracy : {:0.2f}%\".format(accuracy_score(y_pred,y_test)*100))\n",
    "# print(\"cross validation : {:0.2f}%\".format(acuracy.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
